{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning and Organizing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#pre processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#Modeling\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#each data set, not included in github\n",
    "buildMetData = pd.read_csv('energyCSV/building_metadata.csv')\n",
    "samSub = pd.read_csv('energyCSV/sample_submission.csv')\n",
    "test = pd.read_csv('energyCSV/test.csv')\n",
    "train = pd.read_csv('energyCSV/train.csv')\n",
    "weatherTest = pd.read_csv('energyCSV/weather_test.csv')\n",
    "weatherTrain = pd.read_csv('energyCSV/weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the DF size\n",
    "# Code from Kaggle user Koustav Banerjee\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n",
      "Mem. usage decreased to 596.49 Mb (53.1% reduction)\n",
      "Mem. usage decreased to  3.07 Mb (68.1% reduction)\n",
      "Mem. usage decreased to  6.08 Mb (68.1% reduction)\n",
      "Mem. usage decreased to  0.03 Mb (60.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "#Running the function to reduce the memory\n",
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)\n",
    "\n",
    "weatherTrain = reduce_mem_usage(weatherTrain)\n",
    "weatherTest = reduce_mem_usage(weatherTest)\n",
    "buildMetData = reduce_mem_usage(buildMetData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   building_id    int16  \n",
      " 1   meter          int8   \n",
      " 2   timestamp      object \n",
      " 3   meter_reading  float32\n",
      "dtypes: float32(1), int16(1), int8(1), object(1)\n",
      "memory usage: 289.2+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41697600 entries, 0 to 41697599\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   row_id       int32 \n",
      " 1   building_id  int16 \n",
      " 2   meter        int8  \n",
      " 3   timestamp    object\n",
      "dtypes: int16(1), int32(1), int8(1), object(1)\n",
      "memory usage: 596.5+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139773 entries, 0 to 139772\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   site_id             139773 non-null  int8   \n",
      " 1   timestamp           139773 non-null  object \n",
      " 2   air_temperature     139718 non-null  float16\n",
      " 3   cloud_coverage      70600 non-null   float16\n",
      " 4   dew_temperature     139660 non-null  float16\n",
      " 5   precip_depth_1_hr   89484 non-null   float16\n",
      " 6   sea_level_pressure  129155 non-null  float16\n",
      " 7   wind_direction      133505 non-null  float16\n",
      " 8   wind_speed          139469 non-null  float16\n",
      "dtypes: float16(7), int8(1), object(1)\n",
      "memory usage: 3.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 277243 entries, 0 to 277242\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   site_id             277243 non-null  int8   \n",
      " 1   timestamp           277243 non-null  object \n",
      " 2   air_temperature     277139 non-null  float16\n",
      " 3   cloud_coverage      136795 non-null  float16\n",
      " 4   dew_temperature     276916 non-null  float16\n",
      " 5   precip_depth_1_hr   181655 non-null  float16\n",
      " 6   sea_level_pressure  255978 non-null  float16\n",
      " 7   wind_direction      264873 non-null  float16\n",
      " 8   wind_speed          276783 non-null  float16\n",
      "dtypes: float16(7), int8(1), object(1)\n",
      "memory usage: 6.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   site_id      1449 non-null   int8   \n",
      " 1   building_id  1449 non-null   int16  \n",
      " 2   primary_use  1449 non-null   object \n",
      " 3   square_feet  1449 non-null   int32  \n",
      " 4   year_built   675 non-null    float16\n",
      " 5   floor_count  355 non-null    float16\n",
      "dtypes: float16(2), int16(1), int32(1), int8(1), object(1)\n",
      "memory usage: 27.0+ KB\n",
      "None None None None None\n"
     ]
    }
   ],
   "source": [
    "print(train.info(), test.info(), weatherTrain.info(), weatherTest.info(), buildMetData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'timestamp' coloumns in 'train', 'test', 'weatherTrain', 'weatherTest' - as well as the column 'primary_use' in BuildMetData - are currently an onject type. Need to change those formats into something more usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "\n",
    "weatherTrain['timestamp'] = pd.to_datetime(weatherTrain['timestamp'])\n",
    "weatherTest['timestamp'] = pd.to_datetime(weatherTest['timestamp'])\n",
    "\n",
    "buildMetData['primary_use'] = buildMetData['primary_use'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Dtype         \n",
      "---  ------         -----         \n",
      " 0   building_id    int16         \n",
      " 1   meter          int8          \n",
      " 2   timestamp      datetime64[ns]\n",
      " 3   meter_reading  float32       \n",
      "dtypes: datetime64[ns](1), float32(1), int16(1), int8(1)\n",
      "memory usage: 289.2 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41697600 entries, 0 to 41697599\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   row_id       int32         \n",
      " 1   building_id  int16         \n",
      " 2   meter        int8          \n",
      " 3   timestamp    datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int16(1), int32(1), int8(1)\n",
      "memory usage: 596.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 139773 entries, 0 to 139772\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             139773 non-null  int8          \n",
      " 1   timestamp           139773 non-null  datetime64[ns]\n",
      " 2   air_temperature     139718 non-null  float16       \n",
      " 3   cloud_coverage      70600 non-null   float16       \n",
      " 4   dew_temperature     139660 non-null  float16       \n",
      " 5   precip_depth_1_hr   89484 non-null   float16       \n",
      " 6   sea_level_pressure  129155 non-null  float16       \n",
      " 7   wind_direction      133505 non-null  float16       \n",
      " 8   wind_speed          139469 non-null  float16       \n",
      "dtypes: datetime64[ns](1), float16(7), int8(1)\n",
      "memory usage: 3.1 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 277243 entries, 0 to 277242\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   site_id             277243 non-null  int8          \n",
      " 1   timestamp           277243 non-null  datetime64[ns]\n",
      " 2   air_temperature     277139 non-null  float16       \n",
      " 3   cloud_coverage      136795 non-null  float16       \n",
      " 4   dew_temperature     276916 non-null  float16       \n",
      " 5   precip_depth_1_hr   181655 non-null  float16       \n",
      " 6   sea_level_pressure  255978 non-null  float16       \n",
      " 7   wind_direction      264873 non-null  float16       \n",
      " 8   wind_speed          276783 non-null  float16       \n",
      "dtypes: datetime64[ns](1), float16(7), int8(1)\n",
      "memory usage: 6.1 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1449 entries, 0 to 1448\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   site_id      1449 non-null   int8    \n",
      " 1   building_id  1449 non-null   int16   \n",
      " 2   primary_use  1449 non-null   category\n",
      " 3   square_feet  1449 non-null   int32   \n",
      " 4   year_built   675 non-null    float16 \n",
      " 5   floor_count  355 non-null    float16 \n",
      "dtypes: category(1), float16(2), int16(1), int32(1), int8(1)\n",
      "memory usage: 17.9 KB\n",
      "None None None None None\n"
     ]
    }
   ],
   "source": [
    "print(train.info(), test.info(), weatherTrain.info(), weatherTest.info(), buildMetData.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Now, as the data is currently 'timestamp presents itself as a single moment in time. A single hour for every day. this can be broken into further cartegories: 'hour', 'day', 'weekday', & 'month'. This recategorizing could help us find trends in specific, months, days, or even hours for the data to find trends in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216095</th>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>8.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216096</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>4.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216097</th>\n",
       "      <td>1446</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216098</th>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>159.574997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216099</th>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>2.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          building_id  meter           timestamp  meter_reading\n",
       "0                   0      0 2016-01-01 00:00:00       0.000000\n",
       "1                   1      0 2016-01-01 00:00:00       0.000000\n",
       "2                   2      0 2016-01-01 00:00:00       0.000000\n",
       "3                   3      0 2016-01-01 00:00:00       0.000000\n",
       "4                   4      0 2016-01-01 00:00:00       0.000000\n",
       "...               ...    ...                 ...            ...\n",
       "20216095         1444      0 2016-12-31 23:00:00       8.750000\n",
       "20216096         1445      0 2016-12-31 23:00:00       4.825000\n",
       "20216097         1446      0 2016-12-31 23:00:00       0.000000\n",
       "20216098         1447      0 2016-12-31 23:00:00     159.574997\n",
       "20216099         1448      0 2016-12-31 23:00:00       2.850000\n",
       "\n",
       "[20216100 rows x 4 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "train[\"day\"] = train[\"timestamp\"].dt.day\n",
    "train[\"weekend\"] = train[\"timestamp\"].dt.weekday\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "\n",
    "test[\"hour\"] = test[\"timestamp\"].dt.hour\n",
    "test[\"day\"] = test[\"timestamp\"].dt.day\n",
    "test[\"weekend\"] = test[\"timestamp\"].dt.weekday\n",
    "test[\"month\"] = test[\"timestamp\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekend</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216095</th>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216096</th>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>4.825000</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216097</th>\n",
       "      <td>1446</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216098</th>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>159.574997</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20216099</th>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-12-31 23:00:00</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20216100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          building_id  meter           timestamp  meter_reading  hour  day  \\\n",
       "0                   0      0 2016-01-01 00:00:00       0.000000     0    1   \n",
       "1                   1      0 2016-01-01 00:00:00       0.000000     0    1   \n",
       "2                   2      0 2016-01-01 00:00:00       0.000000     0    1   \n",
       "3                   3      0 2016-01-01 00:00:00       0.000000     0    1   \n",
       "4                   4      0 2016-01-01 00:00:00       0.000000     0    1   \n",
       "...               ...    ...                 ...            ...   ...  ...   \n",
       "20216095         1444      0 2016-12-31 23:00:00       8.750000    23   31   \n",
       "20216096         1445      0 2016-12-31 23:00:00       4.825000    23   31   \n",
       "20216097         1446      0 2016-12-31 23:00:00       0.000000    23   31   \n",
       "20216098         1447      0 2016-12-31 23:00:00     159.574997    23   31   \n",
       "20216099         1448      0 2016-12-31 23:00:00       2.850000    23   31   \n",
       "\n",
       "          weekend  month  \n",
       "0               4      1  \n",
       "1               4      1  \n",
       "2               4      1  \n",
       "3               4      1  \n",
       "4               4      1  \n",
       "...           ...    ...  \n",
       "20216095        5     12  \n",
       "20216096        5     12  \n",
       "20216097        5     12  \n",
       "20216098        5     12  \n",
       "20216099        5     12  \n",
       "\n",
       "[20216100 rows x 8 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat-o. Next, concatenating train & test on BuildMetData and the respective weather df so that train and test have all the infomation to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 318. MiB for an array with shape (41697600,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-8c04a0242650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Merging Test, BuildMetData, weatherTest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtestBuild\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuildMetData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'building_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestBuild\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweatherTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'site_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   7944\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7946\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m   7947\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7948\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    882\u001b[0m             )\n\u001b[0;32m    883\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_join_indexers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;34m\"\"\" return the join indexers \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         return _get_join_indexers(\n\u001b[0m\u001b[0;32m    863\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[1;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     }[how]\n\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjoin_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\join.pyx\u001b[0m in \u001b[0;36mpandas._libs.join.left_outer_join\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 318. MiB for an array with shape (41697600,) and data type int64"
     ]
    }
   ],
   "source": [
    "#Merging Train, BuildMetData, weatherTrain\n",
    "trainBuild = train.merge(buildMetData, on=['building_id'], how='left')\n",
    "train = trainBuild.merge(weatherTrain, on=['site_id','timestamp'], how='left')\n",
    "\n",
    "#Merging Test, BuildMetData, weatherTest\n",
    "testBuild = test.merge(buildMetData, on=['building_id'], how='left')\n",
    "test = testBuild.merge(weatherTest, on=['site_id','timestamp'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "buildMetData = pd.read_csv('energyCSV/building_metadata.csv')\n",
    "samSub = pd.read_csv('energyCSV/sample_submission.csv')\n",
    "test = pd.read_csv('energyCSV/test.csv')\n",
    "train = pd.read_csv('energyCSV/train.csv')\n",
    "weatherTest = pd.read_csv('energyCSV/weather_test.csv')\n",
    "weatherTrain = pd.read_csv('energyCSV/weather_train.csv')\n",
    "\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "weatherTrain['timestamp'] = pd.to_datetime(weatherTrain['timestamp'])\n",
    "weatherTest['timestamp'] = pd.to_datetime(weatherTest['timestamp'])\n",
    "buildMetData['primary_use'] = buildMetData['primary_use'].astype('category')\n",
    "\n",
    "train[\"hour\"] = train[\"timestamp\"].dt.hour\n",
    "train[\"day\"] = train[\"timestamp\"].dt.day\n",
    "train[\"weekend\"] = train[\"timestamp\"].dt.weekday\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "test[\"hour\"] = test[\"timestamp\"].dt.hour\n",
    "test[\"day\"] = test[\"timestamp\"].dt.day\n",
    "test[\"weekend\"] = test[\"timestamp\"].dt.weekday\n",
    "test[\"month\"] = test[\"timestamp\"].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp_df = train[['building_id']]\n",
    "temp_df = temp_df.merge(buildMetData, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "trainEx = pd.concat([train, temp_df], axis=1)\n",
    "\n",
    "temp_df = test[['building_id']]\n",
    "temp_df = temp_df.merge(buildMetData, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "testEx = pd.concat([test, temp_df], axis=1)\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp_df = trainEx[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(weatherTrain, on=['site_id','timestamp'], how='left')\n",
    "\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "trainEx = pd.concat([train, temp_df], axis=1)\n",
    "\n",
    "temp_df = testEx[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(weatherTest, on=['site_id','timestamp'], how='left')\n",
    "\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "testEx = pd.concat([test, temp_df], axis=1)\n",
    "\n",
    "del temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple things that need to happen until we can call this data 'clean enough'\n",
    "\n",
    "    - Label encode 'primary_use'\n",
    "    - drop 'timestamp', 'row_id_ & 'site_id' as they are now unnecessary\n",
    "    - drop 'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', & 'floor_count' as they are either\n",
    "    unnecessary or will skew the data more than their worth to fix worth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'primary_use' needs to be label encoded to run a model\n",
    "le = LabelEncoder()\n",
    "\n",
    "train['primary_use'] = le.fit_transform(train['primary_use']).astype(np.int8)\n",
    "test['primary_use'] = le.fit_transform(test['primary_use']).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Tkaing a quick look at the full data before we remove some things\n",
    "train.hist(figsize=(20,20), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropCols = ['precip_depth_1_hr', 'sea_level_pressure', 'wind_direction', 'wind_speed', 'site_id', 'floor_count', 'cloud_coverage']\n",
    "\n",
    "train = train.drop(dropCols, axis = 1)\n",
    "test = test.drop(dropCols + ['row_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Prep\n",
    "scaler = StandardScaler()\n",
    "\n",
    "cats = [\"building_id\", \"primary_use\", \"hour\", \"day\", \"weekend\", \"month\", \"meter\"]\n",
    "nums = [\"square_feet\", \"year_built\", \"air_temperature\", \"cloud_coverage\",\"dew_temperature\"]\n",
    "featCols = cats + nums\n",
    "\n",
    "#Manually train test splitting since the data is pre-separated\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits = num_folds, shuffle = False, random_state = 42)\n",
    "for i, (trainIndex, testIndex) in enumerate(kf.split(train)):\n",
    "    if i + 1 < num_folds:\n",
    "        continue\n",
    "    print(trainIndex.max(), testIndex.min())\n",
    "    \n",
    "    xTrain = train[featCols].iloc[trainIndex]\n",
    "    xTest = train[featCols].iloc[testIndex]\n",
    "    yTrain = test.iloc[trainIndex]\n",
    "    yTest = test.iloc[testIndex]\n",
    "\n",
    "\n",
    "xTrainScaled = scaler.fit_transform(xTrain)\n",
    "xTestScaled = scaler.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg = LogisticRegression(random_state = 123, class_weight = 'balanced')\n",
    "logReg.fit(xTrainScaled, yTrain)\n",
    "\n",
    "yPredTrain = logReg.predict(xTrainScaled)\n",
    "yPredTest = logReg.predict(xTestScaled)\n",
    "\n",
    "#plot_confusion_matrix(logReg, xTestScaled, yTest)\n",
    "\n",
    "print(f\"Accuracy Train Score: {accuracy_score(yTrain, yPredTrain)}\")\n",
    "print(f\"Accuracy Test Score: {accuracy_score(yTest, yPredTest)}\")\n",
    "print('-----')\n",
    "print(f\"F1-Train Score: {f1_score(yTrain, yPredTrain)}\")\n",
    "print(f\"F1-Test Score: {f1_score(yTest, yPredTest)}\")\n",
    "print('-----')\n",
    "print(f\"Precision Train Score: {precision_score(yTrain, yPredTrain)}\")\n",
    "print(f\"Precision Test Score: {precision_score(yTest, yPredTest)}\")\n",
    "print('-----')\n",
    "print(f\"Recall Train Score: {recall_score(yTrain, yPredTrain)}\")\n",
    "print(f\"Recall Test Score: {recall_score(yTest, yPredTest)}\")\n",
    "print('-----')\n",
    "print('0 is \"Not at risk of a stroke\"')\n",
    "print('1 is \"At risk of a stroke\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
